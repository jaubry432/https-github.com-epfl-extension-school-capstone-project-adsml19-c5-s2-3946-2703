{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2258eb6",
   "metadata": {},
   "source": [
    "### EPFL Extension School Applied Data Science: Machine Learning \n",
    "\n",
    "**Capstone proposal** \n",
    "<br> Jerome Aubry, October 2022 \n",
    "\n",
    "## Impact of Pesticide Usage on Fruits/Vegetables and How Level of Pesticides'Predication Can Be Detected on Fruits/Vegetables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58a133",
   "metadata": {},
   "source": [
    "## 1) The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53707b",
   "metadata": {},
   "source": [
    "**The present work presents a machine learning approach to predict the level of pesticide toxicity on some fruits/vegetables and if any trends in pesticides can be detected based on location, type of fruits/vegetables and/or pesticide type**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e27805",
   "metadata": {},
   "source": [
    "Although pesticides provide enough food production to cover the world population’s needs, pesticide concentration is considered to adversely affect the environment in 64% of global agricultural land (24.5 million km2) (1/.). It is a severe cause of soil and water pollution, impacting wildlife, animal and human health directly or indirectly. Risk of cancers and endocrine perturbations can be detected (2/.).\n",
    "\n",
    "As stated by the WHO, 2 million people died in 2019 from being in contact with chemical products (3/.).\n",
    "\n",
    "Some policies in the world and the US are in place to regulate the concentration of pesticides allowed in crops to minimise the impact on human life and the environment (4/.). \n",
    "\n",
    "This is why a systematic approach based on a machine learning algorithm enabling pesticide toxicity detection on fruits/vegetables could help improve future regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59bf99",
   "metadata": {},
   "source": [
    "**Sources**:\n",
    "* 1/. https://www.nature.com/articles/s41561-021-00712-5.pdf \n",
    "* 2/. https://www.eea.europa.eu/ims/pesticides-in-rivers-lakes-and\n",
    "* 3/. https://www.who.int/activities/providing-information-on-the-health-effects-of-chemicals\n",
    "* 4/. https://www.who.int/publications/i/item/9789240005662"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a0e34",
   "metadata": {},
   "source": [
    "## 2) The data\n",
    "\n",
    "### (a) Clear overview of your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f39ad0",
   "metadata": {},
   "source": [
    "**Type of data needed for starting the analysis**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e600c",
   "metadata": {},
   "source": [
    "**The database used for the present analysis is the Pesticide Proprieties Database (PPDB) from the US State of Agriculture department, gathering the concentration of pesticide per class in ppm for several samples of fruits/vegetables/crops. The results are compared to the level of allowed detection/tolerance of pesticide in ppm from different US states and countries. Several labs in the US carried out the analysis.\n",
    "<br> The chosen year is 2015 as providen the most biggest non-value dataset focusing on some samples of fruits/vegetables as shown in Annex II**. \n",
    "\n",
    "> PS: The database is updated on a yearly basis on their website from 1994 onwards. In addition, the data from previous years are modified accordingly if the pesticide regulation has changed, ensuring very good data integrity.\n",
    "\n",
    "Three possible options are possible to extract the data for the analysis:\n",
    "\n",
    "* A/. **Kaggle gathering PPDB in 2015  - <u> This option has been chosen for the present work** </u>:\n",
    "<br> https://www.kaggle.com/datasets/usdeptofag/pesticide-data-program-2015\n",
    "<br> - The data can be downloaded, and database.sqlite is provided where the data are embedded and can be retrieved through Sqlite enquiries. \n",
    "<br> - The data focuses on a selected part of the entire PPDB database, i.e. on some fruits.\n",
    "<br> - In addition, several .csv files are added to the main sqilte file giving information about the meaning of the database's columns. \n",
    "<br> - The csv files are shortly analysed at the beginning of the present file. Otherwise, all of them are downloaded in Annex I for a quick look.\n",
    "\n",
    "> **Remarks**:\n",
    "<br> **It has been noticed that some csv files did not correspond entirely to the data, some information were missing and have been retrieved from the PPDB database itself, This is mentioned at the beginning of the project whereas some csv files has been extended and renames as `extended` and the data integrity is also analysed in Annex II, this has lead to increase the complexity of the analysis**.\n",
    "\n",
    "* B/.**Usage of pesticides for crops in the US per year according to Pesticide Properties DataBase (PPDB)**:\n",
    "<br> https://www.ams.usda.gov/datasets/pdp/pdpdata\n",
    "<br> - The data are compressed and can be easily downloaded per year. the data are in mdb format and can be loaded with a simple function in Jupyter as presented in Annex II. \n",
    "<br> -In addition to the main data, an excel sheet is provided to gather useful explanations for the database columns – the same level of information as the csv files in A/.    \n",
    "<br> - The data content is the same as A/, i.e. focusing on some fruits/vegetables/crops, except that the data can be downloaded annually from 1994 onwards.\n",
    "<br> - For comparison purposes with A/, annexe II provided very fast and quick statistics covering 2015-2020. **It shows that the year 2015 displays the highest numbers of values different from NANs and 0s in column `concen` (target of our analysis); this is the reason why 2015 has been chosen.**\n",
    "\n",
    "* C/. **Online data platform from PPDB**\n",
    "<br> https://apps.ams.usda.gov/pdp\n",
    "<br> Online platform where data can be selected and downloaded. The data are larger than A/. and B/. covering fruits, vegetables, water quality, and crops.\n",
    "<br> Data can be cumbersome and difficult to extract in csv format; this is why option A/. has been chosen, focusing on some fruits/vegeatbles of the dataset.\n",
    "\n",
    "* D/.Annual report 2015 from PPDB:\n",
    "<br> https://www.ams.usda.gov/sites/default/files/media/2015PDPAnnualSummary.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d0bf8",
   "metadata": {},
   "source": [
    "### (b) Plan to manage and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3629fa",
   "metadata": {},
   "source": [
    "- Download the data from the website in csv, sqlite formats\n",
    "- The data are split as follows:\n",
    "> `Results.txt` and `Samples.txt` gathering some pesticides tested for samples of fruits/vegetables.\n",
    "<br> **Results.txt**: \n",
    "<br> The content is as follows: 2333910 rows and 16 columns.\n",
    "<br> Data covering all the pesticides tested on each sample of fruits\n",
    "<br> Target is the column `concen` gathering the concentration in ppm of different pesticides, whereas 38751 out of 2333910 -1.66% values are different from 0. \n",
    "Depending on the database null/empty value in the `concen` column of the downloaded Results dataset (.txt to .mdb) indicates a non-detect - no residue found - and a zero (0) value.\n",
    "<br> **Samples.txt**:\n",
    "<br> The content is as follows: 10187 rows and 18 columns.\n",
    "<br> Down-selected data from `Results.txt` dataset covering information about the location - countries/US state, variety of the fruits and their associated quantity.\n",
    "<br> The two datasets in the downloaded `Samples.txt` and `Results.txt` files can be merged using the value in the `sample_PK` column, which is the first column in both datasets.  The `sample_pk` number is a unique identifier for each analysed sample.  There is one row for each `sample_pk` in the `Sample. txt` dataset and anywhere from 100 to 600 rows for each `sample_pk` in the `Results.txt` file for the many pesticides tested for each sample.\n",
    "- Put in place generic functions for automating the tasks of loading the data, down-select relevant sample analysis -5% of the data, considering only non values of the target column `concen`, display a first statistic analysis as well as merge/aggregate dataset and plot them in a boxplot, barplot, or histogram format for a first EDA analysis including outliers, data exploratories, features by features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d06da2",
   "metadata": {},
   "source": [
    "> **Remarks**: \n",
    "<br> An in-depth EDA has been done done:\n",
    "<br> - a/. Strategy about  NANs, 0s value in columns, replacing with requent values.\n",
    "<br> - b/. Outliers analysis deciding to keep most of the data as part of the ML\n",
    "<br> - c/  Column by column analysis and apply feature engineerings to the numerical/non-numerical columns (cleaning, rearrange columns, for example by region/continent instead of US-state/countries)\n",
    "<br> - d/. Check collinearities, correlations between the numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387b660",
   "metadata": {},
   "source": [
    "## 4) Machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329d1df",
   "metadata": {},
   "source": [
    "### (a) Phrase your project goal as a clear machine learning question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ba1b2",
   "metadata": {},
   "source": [
    "**The target is to train a machine learning algorithm to predict the toxicity levels of pesticide on fruits types based on dataset from 2015**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb491e8b",
   "metadata": {},
   "source": [
    "**It is a supervised/labelled learning approach based on regression models where**:\n",
    "\n",
    "**X = fruits, location, pesticide, regulations ....\n",
    "y_target = concentration level of pesticides in fruits in [ppm]** \n",
    "\n",
    "Several models based on regression can be computed by taking into account:\n",
    "<br> - Data size\n",
    "<br> - Speed\n",
    "<br> - Accuracy\n",
    "\n",
    "The models can be split based on:\n",
    "* Fast but less accurate like for example:\n",
    "<br> Linear Regression - Ridge approach\n",
    "\n",
    "* Accurate but demaning more computation:\n",
    "<br> Random Forest, gradient boosting, k-NN, SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f44b1e",
   "metadata": {},
   "source": [
    "### (b) What models are you planning to use and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65fc98",
   "metadata": {},
   "source": [
    "#### Different models have been tested:\n",
    "Reference: https://medium.com/analytics-vidhya/pros-and-cons-of-popular-supervised-learning-algorithms-d5b3b75d9218\n",
    "\n",
    "\n",
    "\n",
    "**1/.Linear Regression including Ridge approaches**\n",
    "\n",
    "**Pros**:\n",
    "<br> - Easy to implement, give a first baseline\n",
    " \n",
    "**Cons**:\n",
    "<br> - Not so accurate and cannot deal with non-linearity dataset\n",
    "> Remarks:\n",
    "<br> In addition to linearRegression, investigate Ridge and tune hyperparameters\n",
    "\n",
    "\n",
    "**2/. k-NearestNeighbor k-NN**\n",
    "\n",
    "**Pros**:\n",
    "<br> - Simple to implement, can be used for regression as neighbours averaged \n",
    "\n",
    "**Cons**:\n",
    "<br> - Memory consuming since all data are stored at once\n",
    "<br> - Based on distance, outliers can play a role and lead to overfitting results\n",
    "<br> - Suffer when data have very high-dimensions\n",
    "> Remarks:\n",
    "<br> This approach could be problematic depending on our dataset’s size, and we may keep most of the outliers for analysis purposes.\n",
    "\n",
    "\n",
    "**3/. Support Vector Machines SVR for Regression**  \n",
    "\n",
    "**Pros**:\n",
    "<br> - Memory efficient algorithm works well with the high-dimension dataset \n",
    "\n",
    "**Cons**:\n",
    "<br> - Can be time-consuming for large dataset\n",
    "\n",
    "**4/.Random Forest**\n",
    "\n",
    "**Pros**:\n",
    "<br> - Work well with extensive and non-linear datasets \n",
    "<br> - provide good results with outliners, provide good accuracy\n",
    "\n",
    "**Cons**:\n",
    "<br> - Slow training could be problematic with a linear dataset having many features\n",
    "<br> - Provide good results, including outliners.\n",
    "\n",
    "**5/.Gradient Boosting** \n",
    "\n",
    "**Pros**:\n",
    "<br> - Easy to implement and interpret, avoid overfitting\n",
    "\n",
    "**Cons**:\n",
    "<br> - Sequentially adding predictors and each one correcting its predecessors, not so easy to scale up\n",
    "<br> - Sensitive to outliers\n",
    "> Remarks:\n",
    "<br> Never used the algo; it could be an alternative to the random forest and to learn a new technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8b038",
   "metadata": {},
   "source": [
    "### (c) Please tell us your detailed machine learning strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1263b6d",
   "metadata": {},
   "source": [
    "EDA helps to prepare the data to feed into the data pipeline for the machine learning analysis considering the different models presented above\n",
    "\n",
    "**Preprocessing**\n",
    "- Cleaning and preparing the data from EDA (outliers, replace NAN, feature engineering, drop useless information, collinearity checks)\n",
    "- Automatization of the process with functions, if possible\n",
    "\n",
    "**Get baseline/Define metrics**\n",
    "- Pinpoint the columns that correlated the most with the data from the data influencing the results based on `SelectKBest` from the `sklearn` library? Tune the model accordingly\n",
    "- Define appropriate metrics/cost functions - MSE for the models\n",
    "- Get baseline in a similar approach than the project 3\n",
    "\n",
    "**Training/Tuning**\n",
    "- Split the data between train/test depending on the amount of sampling available\n",
    "- Use pipeline process from the `sklearn` library, preprocessing data such as normalisation, PCA analysis if needed \n",
    "- From the models, fine-tune the hyperparameters using the cross-validation, train and tune hyperparameters prior to apply the results to the test data.\n",
    "\n",
    "**Evaluate models and compare results**\n",
    "- Compare results based on chosen metrics in bar plot or similar between different models\n",
    "- Discuss the outlooks. Can we improve the models?\n",
    "- Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714dce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
